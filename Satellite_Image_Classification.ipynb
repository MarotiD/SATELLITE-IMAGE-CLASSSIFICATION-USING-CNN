{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarotiD/SATELLITE-IMAGE-CLASSSIFICATION-USING-CNN/blob/main/Satellite_Image_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63scv1jyd1_g",
        "outputId": "c57d0e29-04d8-41ea-805c-e0af07b92d02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive to access data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths to your directories\n",
        "train_path = '/content/drive/MyDrive/SCT/TRAIN'\n",
        "valid_path = '/content/drive/MyDrive/SCT/VALIDATION'\n",
        "test_path = '/content/drive/MyDrive/SCT/TEST'\n"
      ],
      "metadata": {
        "id": "TuJfZ2r-d_3O"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive to access data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "9MOrdzFaBz1d",
        "outputId": "0950beb5-2711-4d3a-c38e-a4e4f8dd0bb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
      ],
      "metadata": {
        "id": "txKADhBbeHSX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define class names\n",
        "class_names = ['cloudy', 'desert', 'green_area', 'water']\n",
        "\n",
        "# Create ImageDataGenerator for preprocessing\n",
        "image_generator = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input)\n",
        "\n",
        "# Create data generators for training, validation, and testing\n",
        "train_batches = image_generator.flow_from_directory(directory=train_path,\n",
        "                                                     target_size=(224,224),\n",
        "                                                     classes=class_names,\n",
        "                                                     batch_size=30)\n",
        "valid_batches = image_generator.flow_from_directory(directory=valid_path,\n",
        "                                                     target_size=(224,224),\n",
        "                                                     classes=class_names,\n",
        "                                                     batch_size=10)\n",
        "test_batches = image_generator.flow_from_directory(directory=test_path,\n",
        "                                                    target_size=(224,224),\n",
        "                                                    classes=class_names,\n",
        "                                                    batch_size=10,\n",
        "                                                    shuffle=False)"
      ],
      "metadata": {
        "id": "70B6CgFReLGg",
        "outputId": "9683502e-1ea4-4855-bcad-f91bdfde808a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 4 classes.\n",
            "Found 800 images belonging to 4 classes.\n",
            "Found 1200 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imgs,labels=next(train_batches)"
      ],
      "metadata": {
        "id": "UqueTmEVeRnA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this fncn will plot imgs in the form of 1x10 where imgs are placed\n",
        "def plotImages(images_arr):\n",
        "  fig,axes=plt.subplots(1,10,figsize=(20,20))\n",
        "  axes=axes.flatten()\n",
        "  for img,ax in zip(images_arr,axes):\n",
        "    ax.imshow(img)\n",
        "    ax.axis('off')\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "q8AW9cXheyxd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plotImages(imgs)\n",
        "print(labels)"
      ],
      "metadata": {
        "id": "kg0qFOZYgF1d",
        "outputId": "1a43cd12-1086-4174-83e2-a60e5312c280",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 874
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 1. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),  # Convolutional layer with 32 filters, each of size 3x3, ReLU activation, input shape of (224, 224, 3)\n",
        "    MaxPooling2D((2, 2)),  # Max pooling layer with pool size of 2x2\n",
        "    Conv2D(64, (3, 3), activation='relu'),  # Convolutional layer with 64 filters, each of size 3x3, ReLU activation\n",
        "    MaxPooling2D((2, 2)),  # Max pooling layer with pool size of 2x2\n",
        "    Flatten(),  # Flatten layer to convert the 2D output to 1D\n",
        "    Dense(4, activation='softmax')  # Fully connected layer with 5 neurons (for 5 classes) and softmax activation\n",
        "])"
      ],
      "metadata": {
        "id": "xsRvp1UmgLHw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "9zQWVn3ega_E",
        "outputId": "09f9cbd0-5178-464f-f010-f886d45f8b3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 111, 111, 32)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 109, 109, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 54, 54, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 186624)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4)                 746500    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 765892 (2.92 MB)\n",
            "Trainable params: 765892 (2.92 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "lJZp6dUhggAH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(train_batches, validation_data=valid_batches, epochs=10, verbose=1)\n"
      ],
      "metadata": {
        "id": "0UBNRkrwgp2i",
        "outputId": "e8fed250-41a1-4d4b-f830-0928e0e40862",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "67/67 [==============================] - ETA: 0s - loss: 35.8806 - accuracy: 0.6580"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on test data\n",
        "predictions = model.predict(test_batches, verbose=0)"
      ],
      "metadata": {
        "id": "XMNOsMmdgtJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "zJ4MWkYggx0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_true=test_batches.classes, y_pred=np.argmax(predictions, axis=-1))"
      ],
      "metadata": {
        "id": "G9Sxyqkng4Xc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "metadata": {
        "id": "fNyYswuug8F1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm_plot_labels = class_names\n",
        "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')"
      ],
      "metadata": {
        "id": "SBeEJpfthFfk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}